# üì° TelcoVision ‚Äî Documentaci√≥n del Proyecto (Etapas 1 a 6)
![Pipeline](imagenes/Resultado_Pipeline_DagsHub.png)


## 1. Introducci√≥n
El presente proyecto forma parte de la materia **Laboratorio de Miner√≠a de Datos** del Instituto ISTEA y tiene como objetivo reproducir el flujo de trabajo real de un equipo de **MLOps** dedicado al desarrollo de modelos predictivos. La empresa ficticia **TelcoVision**, dedicada a servicios de telecomunicaciones, busca reducir su tasa de **churn** (clientes que se dan de baja). Para ello se provee un dataset de 10.000 clientes con informaci√≥n demogr√°fica, contractual y de uso de servicios.

El proyecto consiste en construir un **pipeline reproducible de Machine Learning** utilizando:
- Versionado de datos con **DVC**
- Control de experimentos (DVC Experiments / MLflow)
- Automatizaci√≥n de CI/CD con **GitHub Actions**
- Sincronizaci√≥n de c√≥digo y datos con **DagsHub**
- Trabajo colaborativo mediante ramas y Pull Requests

Se siguen las Etapas 1 a 6 definidas en la planificaci√≥n del profesor.

---

## 2. Dataset
El dataset base **telco_churn.csv** contiene 10.000 registros con variables demogr√°ficas, de facturaci√≥n y de servicios contratados.

### 2.1. Principales variables
- **customer_id**: identificador del cliente  
- **age**: edad  
- **gender**: g√©nero  
- **region**: regi√≥n geogr√°fica  
- **contract_type**: tipo de contrato  
- **tenure_months**: meses como cliente  
- **monthly_charges**: cargos mensuales  
- **total_charges**: total hist√≥rico facturado  
- **internet_service**: tipo de servicio de internet  
- **phone_service**: servicio telef√≥nico  
- **multiple_lines**: m√∫ltiples l√≠neas telef√≥nicas  
- **payment_method**: m√©todo de pago  
- **churn**: variable objetivo (0 = activo, 1 = baja)

### 2.2. Dataset limpio
El dataset limpio se genera en:

```
data/processed/telco_churn_clean.csv
```

Tras aplicar:
- correcci√≥n de tipos  
- imputaci√≥n de nulos  
- normalizaci√≥n de categor√≠as  
- validaciones de consistencia  

Este archivo est√° versionado con DVC.

---

## 3. Arquitectura del Proyecto y Pipeline

### 3.1. Estructura del repositorio
```
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îú‚îÄ‚îÄ processed/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ data_prep.py
‚îÇ   ‚îú‚îÄ‚îÄ train.py
‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py
‚îú‚îÄ‚îÄ models/
‚îú‚îÄ‚îÄ .github/workflows/
‚îÇ   ‚îî‚îÄ‚îÄ ci.yaml
‚îú‚îÄ‚îÄ params.yaml
‚îú‚îÄ‚îÄ dvc.yaml
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

### 3.2. Pipeline DVC
Stages incluidos:

1. **data_prep** ‚Üí Limpieza de datos  
2. **train** ‚Üí Entrenamiento del modelo  

Representaci√≥n del pipeline:

```
data/raw/*.csv ‚Üí data_prep ‚Üí data/processed/telco_churn_clean.csv ‚Üí train ‚Üí models/model.pkl, metrics.json
```

---

## 4. Etapa 1 ‚Äî Setup Inicial

### Actividades realizadas
‚úîÔ∏è Creaci√≥n del repositorio GitHub  
‚úîÔ∏è Conexi√≥n con DagsHub  
‚úîÔ∏è Inicializaci√≥n de DVC  
‚úîÔ∏è Configuraci√≥n del entorno con `requirements.txt`  
‚úîÔ∏è Definici√≥n de estructura de carpetas  
‚úîÔ∏è Versionado del dataset crudo con DVC  

### Resultado
El proyecto queda preparado para ejecutar el pipeline reproducible.

---

## 5. Etapa 2 ‚Äî Limpieza y Features

### Script utilizado
`src/data_prep.py`

### Transformaciones aplicadas
- Correcci√≥n de tipos num√©ricos  
- Imputaci√≥n de valores faltantes  
- Normalizaci√≥n de categor√≠as  
- Validaci√≥n de rangos  
- Generaci√≥n del dataset limpio  

### Output del stage
```
data/processed/telco_churn_clean.csv
```

Este archivo est√° registrado en DVC.

---

## 6. Etapa 3 ‚Äî Entrenamiento del Modelo

### Script utilizado
`src/train.py`

### Par√°metros del entrenamiento
Definidos en `params.yaml`, por ejemplo:
- tipo de modelo (LogisticRegression)
- regularizaci√≥n
- proporci√≥n de test
- random_state

### Proceso
1. Se lee el dataset limpio.  
2. Se divide en train/test.  
3. Se entrena el modelo configurado.  
4. Se generan m√©tricas en `metrics.json`.  
5. Se guarda el modelo en `models/` y se versiona con DVC.  

### Outputs
- `models/model.pkl`  
- `metrics.json`



---

## 7. Etapa 4 ‚Äî Experimentos
Se realizaron al menos 3 variaciones modificando hiperpar√°metros v√≠a `params.yaml`.  
Los resultados fueron registrados mediante:

- MLflow en DagsHub  

El modelo final se seleccion√≥ comparando accuracy y F1-score.
![Metricas](imagenes/Resultado_Metricas_MlFlow_DagsHub.png)

---

## 8. Etapa 5 ‚Äî CI/CD con GitHub Actions

### Funcionalidad del workflow (`ci.yaml`)
El pipeline ejecuta:
1. Instalaci√≥n de dependencias  
2. `dvc pull`  
3. `dvc repro`  
4. Publicaci√≥n de m√©tricas en los logs del workflow  

Secrets utilizados:
- `DAGSHUB_USER`  
- `DAGSHUB_TOKEN`  

![Repro_Pipeline](imagenes/Resultado_ReproPipeline_GitHubActions.png)

---

## 9. Etapa 6 ‚Äî Iteraci√≥n Colaborativa

### Actividades realizadas
‚úîÔ∏è Creaci√≥n de ramas `feat-*`  
‚úîÔ∏è Pull Requests con validaci√≥n autom√°tica  
‚úîÔ∏è Discusi√≥n de mejoras  
‚úîÔ∏è Merge a `main` condicionado al desempe√±o del modelo  
‚úîÔ∏è Historial documentado del proceso  


En esta estapa se valida cada PR con el archivo validacion_metricas.yaml, si las modificaciones generan mejoras en las metricas del modelo se autoriza el MERGE al main, sino se rechaza el PR.

Validacion TRUE:
![ValidacionMetricasExitoso](imagenes/Resultado_ValidacionMetricasExitoso_GitHubActions.png)

Validacion False:
![ValidacionMetricasFallida](imagenes/Resultado_ValidacionMetricasNegativa_GitHubActions.png)


---

## 10. Conclusiones
## üß† Conclusi√≥n

El desarrollo del proyecto TelcoVision permiti√≥ experimentar de manera pr√°ctica c√≥mo los principios de **MLOps** transforman un proceso de an√°lisis en un sistema productivo, escalable y colaborativo. La construcci√≥n de un **pipeline reproducible** no solo resolvi√≥ la consigna t√©cnica propuesta por el profesor, sino que tambi√©n evidenci√≥ la importancia de contar con procesos automatizados que permitan responder con rapidez a cambios en los datos, en el contexto de negocio y en la realidad operativa de la empresa.

En un entorno real, los datos, los patrones de uso y las condiciones del mercado cambian constantemente. Tener un pipeline versionado con **DVC**, integrado con **CI/CD mediante GitHub Actions**, y monitoreado desde **DagsHub**, permite que cada modificaci√≥n ‚Äîya sea una mejora en la limpieza, un ajuste de hiperpar√°metros o la incorporaci√≥n de nuevas variables‚Äî pueda ser evaluada de forma autom√°tica, objetiva y transparente. Esto habilita algo fundamental en MLOps: **la capacidad de iterar r√°pidamente sin perder control**, manteniendo una trazabilidad completa de modelos, m√©tricas, datos y decisiones tomadas.

Otro aspecto clave es que este pipeline no est√° pensado para una √∫nica persona, sino para un **equipo de cient√≠ficos e ingenieros de datos**. La estructura colaborativa (ramas, pull requests, validaci√≥n autom√°tica de m√©tricas) garantiza que cualquier integrante pueda proponer mejoras sin comprometer la calidad del modelo final. De esta forma, un cambio sugerido por un miembro del equipo no se aprueba por intuici√≥n, sino porque la automatizaci√≥n demuestra que **aporta valor real**. Esto fomenta un flujo de trabajo profesional donde **la evidencia reemplaza a la opini√≥n**.

Durante la implementaci√≥n surgieron m√∫ltiples desaf√≠os: configurar correctamente los remotos de DVC, resolver problemas de compatibilidad con dependencias, manejar la sincronizaci√≥n entre Git y DagsHub, lograr reproducibilidad en diferentes entornos, dise√±ar la comparaci√≥n autom√°tica de m√©tricas y estabilizar el pipeline dentro de GitHub Actions. Cada uno de estos obst√°culos fue una instancia de aprendizaje valiosa, mostrando que **la ingenier√≠a del ecosistema MLOps es tan importante como el modelo mismo**.

Finalmente, este proyecto demuestra la relevancia de contar con herramientas modernas para la gesti√≥n del ciclo de vida de modelos:

- **DVC** para la trazabilidad de datos y modelos  
- **DagsHub** para la visualizaci√≥n, almacenamiento y seguimiento centralizado  
- **GitHub Actions** para orquestar el CI/CD  
- **Versionado de par√°metros, datasets y experimentos** para auditar y reproducir resultados  

En conjunto, estas tecnolog√≠as permitieron construir una soluci√≥n s√≥lida que no solo cumple con la consigna acad√©mica, sino que refleja la manera en que los equipos de datos trabajan en la industria: **r√°pido, colaborativo, reproducible y orientado a mejorar continuamente el desempe√±o del modelo ante una realidad cambiante**.

```
git clone https://github.com/edisonfernandezjef/Telco.git
conda create -n clon python=3.10 -y
conda activate clon
pip install -r requirements.txt
dvc pull
dvc repro
```


